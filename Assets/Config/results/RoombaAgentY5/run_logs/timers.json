{
    "name": "root",
    "gauges": {
        "RoombaAgent.Policy.Entropy.mean": {
            "value": 1.2914683818817139,
            "min": 1.2564213275909424,
            "max": 1.422033667564392,
            "count": 72
        },
        "RoombaAgent.Policy.Entropy.sum": {
            "value": 2546.775634765625,
            "min": 2478.919189453125,
            "max": 2880.052978515625,
            "count": 72
        },
        "RoombaAgent.Step.mean": {
            "value": 143964.0,
            "min": 1955.0,
            "max": 143964.0,
            "count": 72
        },
        "RoombaAgent.Step.sum": {
            "value": 143964.0,
            "min": 1955.0,
            "max": 143964.0,
            "count": 72
        },
        "RoombaAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.415517807006836,
            "min": 0.6539780497550964,
            "max": 2.2679502964019775,
            "count": 72
        },
        "RoombaAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": 63.69830322265625,
            "min": 24.197187423706055,
            "max": 96.59396362304688,
            "count": 72
        },
        "RoombaAgent.Environment.EpisodeLength.mean": {
            "value": 64.73333333333333,
            "min": 56.74285714285714,
            "max": 399.4,
            "count": 72
        },
        "RoombaAgent.Environment.EpisodeLength.sum": {
            "value": 1942.0,
            "min": 1261.0,
            "max": 2739.0,
            "count": 72
        },
        "RoombaAgent.Environment.CumulativeReward.mean": {
            "value": 3.4061333437760672,
            "min": 2.101406253874302,
            "max": 7.961799463629722,
            "count": 72
        },
        "RoombaAgent.Environment.CumulativeReward.sum": {
            "value": 102.18400031328201,
            "min": 32.66799917072058,
            "max": 110.34899905323982,
            "count": 72
        },
        "RoombaAgent.Policy.ExtrinsicReward.mean": {
            "value": 3.4061333437760672,
            "min": 2.101406253874302,
            "max": 7.961799463629722,
            "count": 72
        },
        "RoombaAgent.Policy.ExtrinsicReward.sum": {
            "value": 102.18400031328201,
            "min": 32.66799917072058,
            "max": 110.34899905323982,
            "count": 72
        },
        "RoombaAgent.Losses.PolicyLoss.mean": {
            "value": 0.23815228410659794,
            "min": 0.22778561324983473,
            "max": 0.25801235130333444,
            "count": 72
        },
        "RoombaAgent.Losses.PolicyLoss.sum": {
            "value": 3.810436545705567,
            "min": 3.326690804013809,
            "max": 4.177286345130917,
            "count": 72
        },
        "RoombaAgent.Losses.ValueLoss.mean": {
            "value": 1.238089242539735,
            "min": 0.31490320256653104,
            "max": 1.5493061834255313,
            "count": 72
        },
        "RoombaAgent.Losses.ValueLoss.sum": {
            "value": 19.80942788063576,
            "min": 5.038451241064497,
            "max": 26.338205118234033,
            "count": 72
        },
        "RoombaAgent.Policy.LearningRate.mean": {
            "value": 0.00025708953305349366,
            "min": 0.00025708953305349366,
            "max": 0.0002996857801047399,
            "count": 72
        },
        "RoombaAgent.Policy.LearningRate.sum": {
            "value": 0.0041134325288558985,
            "min": 0.0036835102721633,
            "max": 0.005054256015248,
            "count": 72
        },
        "RoombaAgent.Policy.Epsilon.mean": {
            "value": 0.18569650625,
            "min": 0.18569650625,
            "max": 0.19989526,
            "count": 72
        },
        "RoombaAgent.Policy.Epsilon.sum": {
            "value": 2.9711441,
            "min": 2.6278366999999996,
            "max": 3.384752,
            "count": 72
        },
        "RoombaAgent.Policy.Beta.mean": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005000000000000002,
            "count": 72
        },
        "RoombaAgent.Policy.Beta.sum": {
            "value": 0.008,
            "min": 0.007000000000000003,
            "max": 0.0085,
            "count": 72
        },
        "RoombaAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 72
        },
        "RoombaAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 72
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1718622805",
        "python_version": "3.9.19 (main, Mar 21 2024, 17:21:27) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Yelko\\anaconda3\\envs\\agentjes\\Scripts\\mlagents-learn RoombaAgent.yaml --run-id=RoombaAgentHarderPenalty",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1718629841"
    },
    "total": 7036.0302677,
    "count": 1,
    "self": 0.010405699999864737,
    "children": {
        "run_training.setup": {
            "total": 0.1559436999999999,
            "count": 1,
            "self": 0.1559436999999999
        },
        "TrainerController.start_learning": {
            "total": 7035.8639183000005,
            "count": 1,
            "self": 3.2988963999678163,
            "children": {
                "TrainerController._reset_env": {
                    "total": 13.472895,
                    "count": 1,
                    "self": 13.472895
                },
                "TrainerController.advance": {
                    "total": 7018.874307500032,
                    "count": 146240,
                    "self": 2.6788026000449463,
                    "children": {
                        "env_step": {
                            "total": 6712.152701099886,
                            "count": 146240,
                            "self": 6496.743409799954,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 213.2915102000895,
                                    "count": 146240,
                                    "self": 10.726760500151329,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 202.56474969993818,
                                            "count": 145146,
                                            "self": 202.56474969993818
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.117781099843146,
                                    "count": 146239,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 7016.003005200029,
                                            "count": 146239,
                                            "is_parallel": true,
                                            "self": 697.3397365999817,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.002963299999999336,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0014485999999980237,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0015147000000013122,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0015147000000013122
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 6318.660305300047,
                                                    "count": 146239,
                                                    "is_parallel": true,
                                                    "self": 17.274517600197214,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 17.608773199836804,
                                                            "count": 146239,
                                                            "is_parallel": true,
                                                            "self": 17.608773199836804
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 6232.037858700044,
                                                            "count": 146239,
                                                            "is_parallel": true,
                                                            "self": 6232.037858700044
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 51.73915579996946,
                                                            "count": 146239,
                                                            "is_parallel": true,
                                                            "self": 25.28564680002738,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 26.45350899994208,
                                                                    "count": 584956,
                                                                    "is_parallel": true,
                                                                    "self": 26.45350899994208
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 304.0428038001006,
                            "count": 146239,
                            "self": 4.172578100121427,
                            "children": {
                                "process_trajectory": {
                                    "total": 14.215320199969714,
                                    "count": 146239,
                                    "self": 14.215320199969714
                                },
                                "_update_policy": {
                                    "total": 285.6549055000095,
                                    "count": 1121,
                                    "self": 30.521006900049088,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 255.1338985999604,
                                            "count": 41703,
                                            "self": 255.1338985999604
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.4000006558489986e-06,
                    "count": 1,
                    "self": 1.4000006558489986e-06
                },
                "TrainerController._save_models": {
                    "total": 0.21781800000007934,
                    "count": 1,
                    "self": 0.03999310000017431,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.17782489999990503,
                            "count": 1,
                            "self": 0.17782489999990503
                        }
                    }
                }
            }
        }
    }
}